import os
import json
import faiss
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from google import genai
from functools import lru_cache


# ---------- CONFIG ----------
INDEX_DIR = "index"

TOP_K = 4
FAISS_K = 8

EMBED_MODEL_PATH = "./models/all-MiniLM-L6-v2"
LLM_MODEL = "models/gemini-3-pro-preview"

LAYER_PRIORITY = ["meta", "synth", "raw"]


# ---------- RAG SYSTEM ----------
SYSTEM_RULES = """
Odpov√≠dej POUZE z poskytnut√©ho kontextu.

Nesm√≠≈° dopl≈àovat extern√≠ znalosti.
Nesm√≠≈° m√≠chat epistemick√© vrstvy.

Pokud kontext nestaƒç√≠:
NEDOLO≈ΩENO ‚Äì odpovƒõƒè nen√≠ v datech.

Nikdy nespekuluj.
"""


# ---------- SECOND BRAIN ----------
REASONER_SYSTEM = """
CONTEXT (anchor all replies here):
The user is a digital content creator who has just experienced a FIRST MAJOR VIRAL EVENT (example: Facebook video ‚â• ~1M views). Phase: EARLY VIRAL EXPOSURE.

Typical features of this phase:
- low media experience and limited contract/legal literacy
- high emotional arousal and compressed decision time
- sudden offers, attention spikes, and predatory actors (agencies, scams, exclusivity)
- decisions often made under cognitive overload

SCOPE (allowed actions):
- Map the RISK SPACE and POSSIBLE ADAPTATIONS specific to a creator in early viral exposure.
- Use knowledge from: cognitive psychology, behavioral economics, decision science, social dynamics, reputation mechanics.
- If local indexed evidence is missing, you may infer, BUT ONLY AS CLEARLY MARKED "Modelov√Ω prior".

FORBIDDEN:
- Give legal, medical, or sports instructions presented as prescriptive advice.
- Make single-person deterministic predictions ("will"/"never").
- Use motivational, persuasive, or marketing language.
- Mix epistemic layers (RAW / SYNTH / META) inside one sentence without explicit tags.

EPISTEMIC RULES (must follow for every claim):
Each claim MUST include compact meta-data:
1) CLAIM TYPE: {Modelov√Ω prior | Strong generalization | Weak inference | Speculation}
2) CERTAINTY: {low | medium | higher}
3) MEDIAN (base rate): 1 short sentence or a cautious % (only if empirical).
4) EXTREME (tail): 1 short sentence describing a less-likely high-impact case.
5) LIMITS: 1 short sentence: what we do NOT know / when this may not hold.

SIGNAL STRENGTH (for each claim): {WEAK | MODERATE | STRONG}
- STRONG = direct local RAW evidence or repeated SYNTH consistent across sources.
- MODERATE = repeated SYNTH without RAW or model prior with reasonable mechanistic support.
- WEAK = model prior or speculation without local support.

OUTPUT FORMAT (strict ‚Äî responses must follow this template exactly):
- TITUL: single-line title summarizing the risk/adaptation (‚â§10 words).
- 3‚Äì6 BULLET POINTS. Each point:
  * 1 short sentence describing the risk/adaptation.
  * On the next line: the epistemic tag block:
    [TYPE: <...> | CERTAINTY: <...> | SIGNAL: <...>]
    MEDIAN: <1 sentence> ¬∑ EXTREME: <1 sentence> ¬∑ LIMITS: <1 sentence>
- CO JE NEZN√ÅMO: 2‚Äì4 bullet items (very short).
- KDE HLEDAT D≈ÆKAZY: 1‚Äì3 concrete suggestions (document types / methods).
- ACTIONABILITY: one sentence ‚Äî either "NEDOSTATEƒåN√Å DATA" or "POSSIBLE ADAPTIONS (mapa, not advice)".
- CALIBRATION SCORE: append "CALIBRATION SCORE: <1|2|3> ‚Äî <one-line reason>"

LANGUAGE:
- Produce the user-facing answer in **Czech**. (This is mandatory.)
- System messages/prompts may be in English; user output must be Czech.

HARD CONSTRAINTS:
- Do NOT combine data-sourced claims and model priors in a single sentence; separate them into distinct bullets.
- If output calibration score is 1 (WEAK signal), include NOTE: "NOTE: vysok√° m√≠ra spekulace ‚Äî oznaƒçeno jako Modelov√Ω prior."
- Prefer MEDIAN-focused explanations; include EXTREME only when mechanistically plausible.
- To avoid epistemic paralysis, do not enumerate many fringe hypotheses‚Äîif one dominant mechanism explains the phenomenon, prioritize it.
- Do not overproduce extreme scenarios. If an EXTREME is included, it MUST be mechanistically supported and flagged as such.

INFERENCE GATE (required checks before issuing claims):
1) Is there directly relevant local evidence in the index (RAW/SYNTH/META)? If YES, use it and tag accordingly.
2) If not, verify the mechanism is grounded in behavioral/decision science. If NO, mark as SPECULATION and avoid strong claims.
3) Do not inflate tail risks without mechanistic support.

FINAL NOTE ON STYLE:
- Tone: analytical, concise, non-prescriptive.
- Prioritize clarity over exhaustive listing.
- If forced to choose between being epistemically conservative or more complete, prefer conservative (less claim inflation).
"""



REASONER_WRAPPER = """
EVIDENCE PREFERENCE & USAGE RULES:
1) Local RAW evidence in index ‚Üí use PRIMARILY. Tag inline as: [RAW|<source_file.txt>].
2) Local SYNTH evidence (repeating patterns) ‚Üí use for median claims. Tag: [SYNTH|<source_file.txt>].
3) Local META evidence (limits, biases) ‚Üí give PRIORITY in interpretation. Tag: [META|<source_file.txt>].
4) If using model knowledge (non-local), always mark: Modelov√Ω prior and include LIMITS and SIGNAL.

OUTPUT TEMPLATE (enforce exactly):
- TITUL: 1 line (‚â§10 words)
- BODY: 3‚Äì6 bullets. Each bullet:
  - Short sentence describing the risk/adapt.
  - Epistemic meta-block (exact format):
    [TYPE: <Modelov√Ω prior|Strong generalization|Weak inference|Speculation> | CERTAINTY: <low|medium|higher> | SIGNAL: <WEAK|MODERATE|STRONG>]
    MEDIAN: <1 sentence> ¬∑ EXTREME: <1 sentence> ¬∑ LIMITS: <1 sentence>
- CO JE NEZN√ÅMO: 2‚Äì4 short bullets
- KDE HLEDAT D≈ÆKAZY: 1‚Äì3 concrete document types / methods (e.g., "kopie smlouvy", "soudn√≠ spisy", "rozhovor s b√Ωval√Ωm tv≈Ørcem")
- ACTIONABILITY: one sentence ‚Äî "NEDOSTATEƒåN√Å DATA" or "POSSIBLE ADAPTIONS (mapa, not advice)"
- CALIBRATION SCORE: append "CALIBRATION SCORE: <1|2|3> ‚Äî <one-line reason>"

ADDITIONAL RULES (enforced):
- If local data directly answers question ‚Üí answer briefly (1‚Äì3 sentences) and append a META block (TYPE/CERTAINTY/LIMITS) with inline tag [RAW|file].
- If local data is insufficient ‚Üí DO NOT fabricate facts. Use the INFERENCE GATE and produce a risk map composed only of labeled Modelov√© priory.
- Never mix RAW and Modelov√Ω prior in one sentence. If both are relevant, separate them into distinct bullets explicitly tagged.
- Inline tags for local evidence must be present wherever claims use index content, e.g., [RAW|knowledge/3_index_ready/raw/vyzkumyraw.txt].

ANTI-CATASTROPHE & PARALYSIS CONTROLS:
- Do not overproduce extreme/tail scenarios without clear mechanistic support.
- Prefer median explanations; include extremes only when the mechanism justifies them.
- If one mechanism strongly explains the issue, avoid piling secondary fringe hypotheses.
- If generating many model priors, prioritize and label the top 2‚Äì3 by SIGNAL strength.

CALIBRATION GUIDELINES:
- 3 = STRONG (direct RAW or repeated SYNTH)
- 2 = MODERATE (SYNTH without RAW, or mechanistic model prior)
- 1 = WEAK (only model priors / speculation) ‚Üí include explicit NOTE about high speculation.

TECHNICAL INSTRUCTION FOR CALLER:
- Send REASONER_SYSTEM as primary system message (English).
- Send REASONER_WRAPPER as an additional system/context message (English).
- Then send user query in Czech. Model must reply in Czech, following the template.

TRUSTWORTHINESS NOTE:
- If forced to trade off between satisfying the output template and avoiding unsupported claims, avoid unsupported claims. The template is secondary to epistemic conservatism.

USAGE SUMMARY:
- This wrapper enforces that the model acts as a risk-mapping engine (not an advice engine). Keep outputs short, structured, and explicitly labeled.
"""



LAYERS_EXPLANATION = """ RAW = pouze pozorovateln√© jevy SYNTH = opakuj√≠c√≠ se vzorce bez hodnocen√≠ META = limity pozn√°n√≠ a zkreslen√≠ Pokud odpovƒõƒè nen√≠ v datech ‚Üí NEDOLO≈ΩENO """
TOPICS = """

# üß† TRAJEKTORIE POZORNOSTI

1. Roste moje viditelnost rychleji ne≈æ moje schopnost ji un√©st?
2. Je souƒçasn√° pozornost stabiln√≠ jev, nebo kr√°tkodob√Ω spike?
3. Co se stane s mou identitou, pokud pozornost zmiz√≠ stejnƒõ rychle, jako p≈ôi≈°la?
4. Reaguje publikum na obsah ‚Äî nebo u≈æ reaguje na mƒõ jako osobu?
5. Kolik kontroly m√°m nad t√≠m, proƒç mƒõ lid√© sleduj√≠?
6. Co se zmƒõn√≠, pokud se narativ kolem m√© osoby otoƒç√≠?
7. Jak by vypadal stejn√Ω vir√°l bez algoritmick√©ho boostu?

---

# ‚ö†Ô∏è ROZHODOV√ÅN√ç POD TLAKEM

8. Rozhoduji se jinak ne≈æ p≈ôed mƒõs√≠cem?
9. Kolik ƒçasu si re√°lnƒõ d√°v√°m na velk√° rozhodnut√≠?
10. Je pocit urgence skuteƒçn√Ω ‚Äî nebo soci√°lnƒõ vytvo≈ôen√Ω?
11. Kter√° rozhodnut√≠ dƒõl√°m bez pln√©ho porozumƒõn√≠ n√°sledk≈Ø?
12. Jak by tato volba vypadala, kdyby nebyla ≈æ√°dn√° viralita?
13. Reaguji ‚Äî nebo vyb√≠r√°m?
14. Co dnes pova≈æuji za ‚Äûneopakovatelnou p≈ô√≠le≈æitost‚Äú?

---

# ü™û PERCEPƒåN√ç ZKRESLEN√ç

15. Zamƒõ≈àuji viditelnost za hodnotu?
16. Zamƒõ≈àuji r≈Øst publika za d≈Økaz kompetence?
17. Jak by m√© souƒçasn√© kroky hodnotilo m√© ‚Äûp≈ôedvir√°ln√≠ j√°‚Äú?
18. Vƒõ≈ô√≠m sign√°l≈Øm ‚Äî nebo dat≈Øm?
19. Kolik m√©ho sebeobrazu je teƒè z√°visl√© na metrik√°ch?
20. Reaguji v√≠ce na realitu, nebo na koment√°≈ôe?
21. Jak moc se zmƒõnilo m√© vn√≠m√°n√≠ rizika?

---

# üí∞ NAB√çDKY A ASYMETRIE

22. Kdo m√° z t√©to nab√≠dky struktur√°lnƒõ vƒõt≈°√≠ v√Ωhodu?
23. Rozum√≠m motivaci druh√© strany ‚Äî nebo ji jen odhaduji?
24. Proƒç tato nab√≠dka existuje pr√°vƒõ teƒè?
25. Co v√≠ druh√° strana, co j√° nev√≠m?
26. Kter√© z√°vazky mohou p≈ôe≈æ√≠t samotnou viralitu?
27. Kolik prostoru m√°m ≈ô√≠ct ‚Äûne‚Äú?
28. Jak by tato dohoda vypadala bez ƒçasov√©ho tlaku?

---

# üß© STRUKTUR√ÅLN√ç NEJISTOTA

29. Jak velk√° ƒç√°st tohoto prost≈ôed√≠ je pro mƒõ neviditeln√°?
30. Kolik p≈ô√≠bƒõh≈Ø p≈ôe≈æiv≈°√≠ch formuje mou p≈ôedstavu reality?
31. Kdo zmizel ‚Äî a proƒç o nich nev√≠m?
32. Jak reprodukovateln√Ω je m≈Øj √∫spƒõch?
33. Co zde nelze predikovat?
34. Kde operuji ƒçistƒõ v nezn√°mu?

---

# üë§ IDENTITA A HRANICE

35. Kde konƒç√≠m j√° a zaƒç√≠n√° moje ve≈ôejn√° persona?
36. Kolik soukrom√≠ jsem ochoten vymƒõnit za r≈Øst?
37. Co z dne≈°ka bude existovat online i za deset let?
38. Jak√© informace u≈æ nelze vz√≠t zpƒõt?
39. Buduji obraz ‚Äî nebo kari√©ru?
40. Kdo kontroluje narativ o mnƒõ?

---

# üîÑ ADAPTACE VS. REAKTIVITA

41. Mƒõn√≠m strategii ‚Äî nebo jen has√≠m reakce publika?
42. P≈ôizp≈Øsobuji obsah ‚Äî nebo sebe?
43. Jak stabiln√≠ je m≈Øj souƒçasn√Ω smƒõr?
44. Co se stane, kdy≈æ p≈ôestanu optimalizovat pro odezvu?

---

# üß† KAPACITA A REALITA

45. Roste objem m√Ωch rozhodnut√≠ rychleji ne≈æ moje ment√°ln√≠ kapacita?
46. Kolik prostoru mi zb√Ωv√° na promy≈°len√© kroky?
47. Kdo mi pom√°h√° p≈ôem√Ω≈°let ‚Äî ne jen reagovat?
48. Zmen≈°uje se m≈Øj svƒõt na digit√°ln√≠ prost≈ôed√≠?

---

# üåä LONG-TERM TRAJEKTORIE

49. Pokud by tato vlna skonƒçila z√≠tra ‚Äî co mi z≈Østane?
50. Stav√≠m nƒõco, co p≈ôe≈æije samotnou pozornost?

"""

# ---------- LOAD ----------
load_dotenv()

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

embed_model = SentenceTransformer(EMBED_MODEL_PATH)

index = faiss.read_index(os.path.join(INDEX_DIR, "faiss.index"))

with open(os.path.join(INDEX_DIR, "chunks.json"), "r", encoding="utf-8") as f:
    chunks = json.load(f)


# ---------- CACHE ----------
@lru_cache(maxsize=512)
def embed_question_cached(question: str):
    return embed_model.encode(
        [question],
        normalize_embeddings=True
    ).astype("float32")


# ---------- REASONER ----------
def run_reasoner(question: str):

    prompt = f"""
{REASONER_SYSTEM}

{REASONER_WRAPPER}

OT√ÅZKA:
{question}
"""

    try:
        response = client.models.generate_content(
            model=LLM_MODEL,
            contents=prompt
        )

        if not response.text:
            return "Epistemick√Ω prostor je p≈ô√≠li≈° ≈ô√≠dk√Ω pro smysluplnou inferenci."

        return response.text.strip()

    except Exception as e:
        print("REASONER ERROR:", e)
        return "Reasoner doƒçasnƒõ nedostupn√Ω."


# ---------- LAYER CLASSIFIER ----------
def classify_question(question: str) -> list[str]:

    q = question.lower()

    if any(x in q for x in [
        "pozorov√°no",
        "zaznamen√°no",
        "p≈ô√≠pady",
        "ud√°losti"
    ]):
        return ["raw", "synth"]

    if any(x in q for x in [
        "jak",
        "proƒç",
        "vzorce"
    ]):
        return ["synth", "meta"]

    if any(x in q for x in [
        "nev√≠me",
        "zkreslen√≠",
        "limity"
    ]):
        return ["meta", "synth"]

    return ["synth"]


# ---------- CORE ----------
def ask(question: str) -> str:

    if not question.strip():
        return "Pr√°zdn√Ω dotaz."

    allowed_layers = classify_question(question)

    q_vec = embed_question_cached(question)

    distances, indices = index.search(q_vec, FAISS_K)

    if indices.size == 0:
        return run_reasoner(question)

    candidates = [chunks[i] for i in indices[0]]

    filtered = [
        c for c in candidates
        if c.get("layer") in allowed_layers
    ]

    # üëâ pokud nem√°me evidenci ‚Üí druh√Ω mozek
    if not filtered:
        return run_reasoner(question)

    priority_map = {layer: i for i, layer in enumerate(LAYER_PRIORITY)}

    filtered.sort(
        key=lambda c: priority_map.get(c["layer"], 999)
    )

    context_docs = filtered[:TOP_K]

    context = "\n\n".join(
        f"[VRSTVA: {c['layer']}]\n{c['text']}"
        for c in context_docs
    )

    prompt = f"""{SYSTEM_RULES}

KONTEXT:
{context}

OT√ÅZKA:
{question}
"""

    try:

        response = client.models.generate_content(
            model=LLM_MODEL,
            contents=prompt
        )

        if not response.text:
            return run_reasoner(question)

        text = response.text.strip()

        # üî• kritick√° pojistka
        if "NEDOLO≈ΩENO" in text:
            return run_reasoner(question)

        return text

    except Exception as e:

        print("LLM ERROR:", e)

        return run_reasoner(question)
