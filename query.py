import os
import json
import faiss
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from google import genai
from functools import lru_cache


# ---------- CONFIG ----------
INDEX_DIR = "index"

TOP_K = 4
FAISS_K = 8

embed_model = SentenceTransformer("all-MiniLM-L6-v2")

LLM_MODEL = "models/gemini-3-pro-preview"

LAYER_PRIORITY = ["meta", "synth", "raw"]


# ---------- RAG SYSTEM ----------
SYSTEM_RULES = """
OdpovÃ­dej POUZE z poskytnutÃ©ho kontextu.

NesmÃ­Å¡ doplÅˆovat externÃ­ znalosti.
NesmÃ­Å¡ mÃ­chat epistemickÃ© vrstvy.

Pokud kontext nestaÄÃ­:
NEDOLOÅ½ENO â€“ odpovÄ›Ä nenÃ­ v datech.

Nikdy nespekuluj.
"""


# ---------- SECOND BRAIN (CZ, final) ----------
REASONER_SYSTEM = """
KONtext (ukotvi vÅ¡echny odpovÄ›di sem):
UÅ¾ivatel je tvÅ¯rce digitÃ¡lnÃ­ho obsahu, kterÃ½ prÃ¡vÄ› zaÅ¾il PRVNÃ VELKÃ VIRÃL (napÅ™. video na Facebooku â‰¥ ~1M zhlÃ©dnutÃ­). FÃ¡ze: RANÃ VIRÃLNÃ EXPOZICE.

TypickÃ© rysy tÃ©to fÃ¡ze:
- malÃ¡ mediÃ¡lnÃ­ zkuÅ¡enost, omezenÃ¡ smluvnÃ­/prÃ¡vnÃ­ gramotnost
- vysokÃ¡ emoÄnÃ­ aktivace, zhuÅ¡tÄ›nÃ½ Äas pro rozhodovÃ¡nÃ­
- nÃ¡hlÃ© nabÃ­dky, exploatativnÃ­ aktÃ©Å™i
- rozhodnutÃ­ Äasto pod kognitivnÃ­m pÅ™etÃ­Å¾enÃ­m

POVOLENÃ‰ ÄŒINNOSTI:
- Mapovat RIZIKOVÃ PROSTOR a NAVRHOVAT MOÅ½NÃ‰ KROKY (mapa, ne rady).
- PouÅ¾Ã­t znalosti z: kognitivnÃ­ psychologie, behaviorÃ¡lnÃ­ ekonomie, decision science, sociÃ¡lnÃ­ dynamiky, reputaÄnÃ­ mechaniky.
- Pokud chybÃ­ lokÃ¡lnÃ­ dÅ¯kazy, lze inferovat s jasnÃ½m Å¡tÃ­tkem "ModelovÃ½ prior".

ZAKÃZÃNO:
- PÅ™edepisovat prÃ¡vnÃ­, lÃ©kaÅ™skÃ¡ nebo sportovnÃ­ doporuÄenÃ­.
- Deterministicky pÅ™edpovÃ­dat osud jedinÃ© osoby ("bude"/"nikdy").
- PouÅ¾Ã­vat motivujÃ­cÃ­ Äi marketingovÃ½ jazyk.
- MÃ­chat epistemickÃ© vrstvy (RAW/SYNTH/META) bez explicitnÃ­ho oznaÄenÃ­.

EPISTEMICKÃ PRAVIDLA (povinnÃ¡ pro kaÅ¾dÃ© tvrzenÃ­):
KaÅ¾dÃ© tvrzenÃ­ musÃ­ obsahovat krÃ¡tkÃ¡ metadata:
- TYPE: {ModelovÃ½ prior | Strong generalization | Weak inference | Speculation}
- CERTAINTY: {nÃ­zkÃ¡ | stÅ™ednÃ­ | vyÅ¡Å¡Ã­}
- SIGNAL: {WEAK | MODERATE | STRONG}
- MEDIÃN (base rate): 1 vÄ›ta
- EXTRÃ‰M (tail): 1 vÄ›ta
- HRANICE POZNÃNÃ: 1 vÄ›ta (co nevÃ­me)

PRAVIDLA UX (aplikovat na uÅ¾ivatelskÃ½ vÃ½stup):
- VÃSTUP POUZE Äesky.
- Na zaÄÃ¡tku PRECHECK zobraz tÅ™i tokeny (perceptuÃ¡lnÃ­ kotvy):
  RIZIKOVÃ HUSTOTA: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>
  VOLATILITA PROSTÅ˜EDÃ: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>
  PREDIKOVATELNOST: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>
- PouÅ¾Ã­vej krÃ¡tkÃ© vÄ›ty a hodnÄ› bÃ­lÃ©ho mÃ­sta (dvÄ›â€“tÅ™i krÃ¡tkÃ© vÄ›ty â†’ mezera).
- Nejprve vysvÄ›tli lidsky, pak pojmenuj termÃ­n v zÃ¡vorce.
- ZAKÃZAT angliÄtinu ve vÃ½stupu; pokud internÄ› pouÅ¾Ã­vÃ¡Å¡ EN tokeny, NEMÄšÅ‡ je do uÅ¾ivatelskÃ©ho textu.
- Nahrazuj tyto anglickÃ© tokeny tÄ›mito ÄeskÃ½mi:
  ACTIONABILITY â†’ CO Z TOHO PLYNE
  POSSIBLE ADAPTATIONS â†’ MOÅ½NÃ‰ KROKY
  CALIBRATION â†’ EPISTEMICKÃ SPOLEHLIVOST
  LIMITS â†’ HRANICE POZNÃNÃ
  MEDIAN â†’ NEJÄŒASTÄšJÅ Ã SCÃ‰NÃÅ˜
  EXTREME â†’ MÃ‰NÄš ÄŒASTÃ, ALE NEBEZPEÄŒNÃ
- DÃ©lka vÃ½stupu max ~3000 znakÅ¯; pokud pÅ™ekroÄÃ­Å¡, ukonÄi s "[TRUNCATED]" a ukaÅ¾, kde jsou zdroje.

VÃKONNOSTNÃ BRZDY:
- Nikdy nepouÅ¡tÄ›j nevÄ›rohodnÃ© tvrzenÃ­ jen aby se vyplnil Å¡ablonovÃ½ blok.
- Pokud chybÃ­ data â†’ pouÅ¾ij explicitnÃ­ "NEDOSTATEÄŒNÃ DATA" nebo oznaÄ â€ModelovÃ½ priorâ€œ.

TÃ“N:
- AnalytickÃ½, struÄnÃ½, nepreskriptivnÃ­.
"""

# ---------- WRAPPER (evidence usage & template enforcement) ----------
REASONER_WRAPPER = """
EVIDENCE & VÃSTUPNÃ Å ABLONA (povinnÃ©)

POUÅ½ITÃ DÅ®KAZÅ® (pÅ™Ã­snÃ©):
1) Pokud v indexu existuje relevantnÃ­ lokÃ¡lnÃ­ RAW â†’ pouÅ¾ij ho; v textu taguj pÅ™esnÄ›: [RAW|cesta/k/souboru.txt]
2) Pokud existuje lokÃ¡lnÃ­ SYNTH â†’ pouÅ¾ij pro mediÃ¡novÃ¡ tvrzenÃ­; taguj: [SYNTH|cesta]
3) Pokud existuje lokÃ¡lnÃ­ META â†’ pouÅ¾ij pro interpretaci; taguj: [META|cesta]
4) Pokud Å¾Ã¡dnÃ© lokÃ¡lnÃ­ dÅ¯kazy â†’ oznaÄ tvrzenÃ­ jako ModelovÃ½ prior a useÄ SIGNAL a LIMITS.

VÃSTUPNÃ Å ABLONA (pÅ™esnÄ› dodrÅ¾et; ÄeÅ¡tina):
- TITUL: <krÃ¡tkÃ½ nÃ¡zev â‰¤6 slov>

- PERCEPTUÃLNÃ KOTVY:
  RIZIKOVÃ HUSTOTA: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>
  VOLATILITA PROSTÅ˜EDÃ: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>
  PREDIKOVATELNOST: <nÃ­zkÃ¡/stÅ™ednÃ­/vysokÃ¡>

- MAPA â€” CO SE PRAVDÄšPODOBNÄš DÄšJE
  (3â€“6 KARET; kaÅ¾dÃ½ card pÅ™esnÄ› tÃ­mto formÃ¡tem:)

  ğŸ”¹ Mechanismus: <nÃ¡zev>
  TYPE: <ModelovÃ½ prior|Strong generalization|Weak inference|Speculation>
  CERTAINTY: <nÃ­zkÃ¡|stÅ™ednÃ­|vyÅ¡Å¡Ã­>
  SIGNAL: <WEAK|MODERATE|STRONG>

  MEDIÃN:
  <jedna krÃ¡tkÃ¡ vÄ›ta>

  EXTRÃ‰M:
  <jedna krÃ¡tkÃ¡ vÄ›ta>

  HRANICE POZNÃNÃ:
  <jedna krÃ¡tkÃ¡ vÄ›ta>

  (Opakuj pro kaÅ¾dou kartu; NEPÃÅ  MEDIÃN/EXTRÃ‰M/LIMITS inline.)

- CO JE NEZNÃMO:
  â€¢ <krÃ¡tkÃ½ bod 1>
  â€¢ <krÃ¡tkÃ½ bod 2>
  â€¢ <volitelnÄ› bod 3>

- KDE BY Å LA ZÃSKAT JISTOTA:
  â€¢ <konkrÃ©tnÃ­ dokument / metoda 1>
  â€¢ <konkrÃ©tnÃ­ dokument / metoda 2>

- DISTRIBUÄŒNÃ REALITA:
  MediÃ¡n: <jedna krÃ¡tkÃ¡ frÃ¡ze>
  ExtrÃ©m: <jedna krÃ¡tkÃ¡ frÃ¡ze>
  (Pozn.: u silnÃ©ho heavy-tail napiÅ¡ "heavy-tail riziko".)

- CO Z TOHO PLYNE:
  "NEDOSTATEÄŒNÃ DATA" NEBO "MOÅ½NÃ‰ KROKY (mapa, ne rada)"

- CALIBRATION SCORE: <1|2|3> â€” <jedna vÄ›ta dÅ¯vod>

DALÅ Ã PRAVIDLA:
- NIKDY nemÃ­chat RAW a ModelovÃ½ prior ve stejnÃ© vÄ›tÄ›. Pokud relevantnÃ­, vytvoÅ™ samostatnÃ© karty s tagy.
- Pokud lokÃ¡lnÃ­ data pÅ™Ã­mo odpovÃ­dajÃ­ dotazu â†’ nejprve 1â€“3 vÄ›ty odpovÄ›di s tagem [RAW|cesta], potom pÅ™idej META kartu.
- Pokud CALIBRATION SCORE = 1 â†’ pÅ™idej poznÃ¡mku: "NOTE: vysokÃ¡ mÃ­ra spekulace â€” oznaÄeno jako ModelovÃ½ prior."
- Pokud je vÃ½stup delÅ¡Ã­ neÅ¾ limit â†’ pÅ™idej "[TRUNCATED]" a uveÄ, kde hledat dalÅ¡Ã­ zdroje (cesty k souborÅ¯m).
- Preferuj Äitelnost: krÃ¡tkÃ© vÄ›ty, mezery mezi bloky, jednoduchÃ¡ slovnÃ­ zÃ¡soba.
- VÃ½stup musÃ­ bÃ½t v ÄeÅ¡tinÄ›; internÃ­ systÃ©movÃ© tokeny lze uchovat v EN, ale NIKDY je neposÃ­lej uÅ¾ivateli.

TECHNICKÃ‰ POUÅ½ITÃ (volajÃ­cÃ­):
- PoÅ¡li REASONER_SYSTEM jako primÃ¡rnÃ­ systÃ©movou zprÃ¡vu.
- PoÅ¡li REASONER_WRAPPER jako sekundÃ¡rnÃ­ systÃ©movou zprÃ¡vu.
- PotÃ© poÅ¡li uÅ¾ivatelÅ¯v dotaz (Äesky). Model musÃ­ odpovÄ›dÄ›t Äesky a pÅ™esnÄ› podle Å¡ablony.
- Pokud je lokÃ¡lnÃ­ dÅ¯kaz pouÅ¾it, zahrÅˆ inline tagy pÅ™esnÄ›: [RAW|path], [SYNTH|path], [META|path].

DÅ®VÄšRYHODNOST:
- UpÅ™ednostni vynucenÃ­ Å¡ablony a epistemickÃ© opatrnosti pÅ™ed plnÄ›nÃ­m formy.
"""



LAYERS_EXPLANATION = """ RAW = pouze pozorovatelnÃ© jevy SYNTH = opakujÃ­cÃ­ se vzorce bez hodnocenÃ­ META = limity poznÃ¡nÃ­ a zkreslenÃ­ Pokud odpovÄ›Ä nenÃ­ v datech â†’ NEDOLOÅ½ENO """
TOPICS = """

# ğŸ§  TRAJEKTORIE POZORNOSTI

1. Roste moje viditelnost rychleji neÅ¾ moje schopnost ji unÃ©st?
2. Je souÄasnÃ¡ pozornost stabilnÃ­ jev, nebo krÃ¡tkodobÃ½ spike?
3. Co se stane s mou identitou, pokud pozornost zmizÃ­ stejnÄ› rychle, jako pÅ™iÅ¡la?
4. Reaguje publikum na obsah â€” nebo uÅ¾ reaguje na mÄ› jako osobu?
5. Kolik kontroly mÃ¡m nad tÃ­m, proÄ mÄ› lidÃ© sledujÃ­?
6. Co se zmÄ›nÃ­, pokud se narativ kolem mÃ© osoby otoÄÃ­?
7. Jak by vypadal stejnÃ½ virÃ¡l bez algoritmickÃ©ho boostu?

---

# âš ï¸ ROZHODOVÃNÃ POD TLAKEM

8. Rozhoduji se jinak neÅ¾ pÅ™ed mÄ›sÃ­cem?
9. Kolik Äasu si reÃ¡lnÄ› dÃ¡vÃ¡m na velkÃ¡ rozhodnutÃ­?
10. Je pocit urgence skuteÄnÃ½ â€” nebo sociÃ¡lnÄ› vytvoÅ™enÃ½?
11. KterÃ¡ rozhodnutÃ­ dÄ›lÃ¡m bez plnÃ©ho porozumÄ›nÃ­ nÃ¡sledkÅ¯?
12. Jak by tato volba vypadala, kdyby nebyla Å¾Ã¡dnÃ¡ viralita?
13. Reaguji â€” nebo vybÃ­rÃ¡m?
14. Co dnes povaÅ¾uji za â€neopakovatelnou pÅ™Ã­leÅ¾itostâ€œ?

---

# ğŸª PERCEPÄŒNÃ ZKRESLENÃ

15. ZamÄ›Åˆuji viditelnost za hodnotu?
16. ZamÄ›Åˆuji rÅ¯st publika za dÅ¯kaz kompetence?
17. Jak by mÃ© souÄasnÃ© kroky hodnotilo mÃ© â€pÅ™edvirÃ¡lnÃ­ jÃ¡â€œ?
18. VÄ›Å™Ã­m signÃ¡lÅ¯m â€” nebo datÅ¯m?
19. Kolik mÃ©ho sebeobrazu je teÄ zÃ¡vislÃ© na metrikÃ¡ch?
20. Reaguji vÃ­ce na realitu, nebo na komentÃ¡Å™e?
21. Jak moc se zmÄ›nilo mÃ© vnÃ­mÃ¡nÃ­ rizika?

---

# ğŸ’° NABÃDKY A ASYMETRIE

22. Kdo mÃ¡ z tÃ©to nabÃ­dky strukturÃ¡lnÄ› vÄ›tÅ¡Ã­ vÃ½hodu?
23. RozumÃ­m motivaci druhÃ© strany â€” nebo ji jen odhaduji?
24. ProÄ tato nabÃ­dka existuje prÃ¡vÄ› teÄ?
25. Co vÃ­ druhÃ¡ strana, co jÃ¡ nevÃ­m?
26. KterÃ© zÃ¡vazky mohou pÅ™eÅ¾Ã­t samotnou viralitu?
27. Kolik prostoru mÃ¡m Å™Ã­ct â€neâ€œ?
28. Jak by tato dohoda vypadala bez ÄasovÃ©ho tlaku?

---

# ğŸ§© STRUKTURÃLNÃ NEJISTOTA

29. Jak velkÃ¡ ÄÃ¡st tohoto prostÅ™edÃ­ je pro mÄ› neviditelnÃ¡?
30. Kolik pÅ™Ã­bÄ›hÅ¯ pÅ™eÅ¾ivÅ¡Ã­ch formuje mou pÅ™edstavu reality?
31. Kdo zmizel â€” a proÄ o nich nevÃ­m?
32. Jak reprodukovatelnÃ½ je mÅ¯j ÃºspÄ›ch?
33. Co zde nelze predikovat?
34. Kde operuji ÄistÄ› v neznÃ¡mu?

---

# ğŸ‘¤ IDENTITA A HRANICE

35. Kde konÄÃ­m jÃ¡ a zaÄÃ­nÃ¡ moje veÅ™ejnÃ¡ persona?
36. Kolik soukromÃ­ jsem ochoten vymÄ›nit za rÅ¯st?
37. Co z dneÅ¡ka bude existovat online i za deset let?
38. JakÃ© informace uÅ¾ nelze vzÃ­t zpÄ›t?
39. Buduji obraz â€” nebo kariÃ©ru?
40. Kdo kontroluje narativ o mnÄ›?

---

# ğŸ”„ ADAPTACE VS. REAKTIVITA

41. MÄ›nÃ­m strategii â€” nebo jen hasÃ­m reakce publika?
42. PÅ™izpÅ¯sobuji obsah â€” nebo sebe?
43. Jak stabilnÃ­ je mÅ¯j souÄasnÃ½ smÄ›r?
44. Co se stane, kdyÅ¾ pÅ™estanu optimalizovat pro odezvu?

---

# ğŸ§  KAPACITA A REALITA

45. Roste objem mÃ½ch rozhodnutÃ­ rychleji neÅ¾ moje mentÃ¡lnÃ­ kapacita?
46. Kolik prostoru mi zbÃ½vÃ¡ na promyÅ¡lenÃ© kroky?
47. Kdo mi pomÃ¡hÃ¡ pÅ™emÃ½Å¡let â€” ne jen reagovat?
48. ZmenÅ¡uje se mÅ¯j svÄ›t na digitÃ¡lnÃ­ prostÅ™edÃ­?

---

# ğŸŒŠ LONG-TERM TRAJEKTORIE

49. Pokud by tato vlna skonÄila zÃ­tra â€” co mi zÅ¯stane?
50. StavÃ­m nÄ›co, co pÅ™eÅ¾ije samotnou pozornost?

"""

# ---------- LOAD ----------
load_dotenv()

client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

EMBED_MODEL_PATH = "all-MiniLM-L6-v2"


index = faiss.read_index(os.path.join(INDEX_DIR, "faiss.index"))

with open(os.path.join(INDEX_DIR, "chunks.json"), "r", encoding="utf-8") as f:
    chunks = json.load(f)


# ---------- CACHE ----------
@lru_cache(maxsize=512)
def embed_question_cached(question: str):
    return embed_model.encode(
        [question],
        normalize_embeddings=True
    ).astype("float32")


# ---------- REASONER ----------
def run_reasoner(question: str):

    prompt = f"""
{REASONER_SYSTEM}

{REASONER_WRAPPER}

OTÃZKA:
{question}
"""

    try:
        response = client.models.generate_content(
            model=LLM_MODEL,
            contents=prompt
        )

        if not response.text:
            return "EpistemickÃ½ prostor je pÅ™Ã­liÅ¡ Å™Ã­dkÃ½ pro smysluplnou inferenci."

        return response.text.strip()

    except Exception as e:
        print("REASONER ERROR:", e)
        return "Reasoner doÄasnÄ› nedostupnÃ½."


# ---------- LAYER CLASSIFIER ----------
def classify_question(question: str) -> list[str]:

    q = question.lower()

    if any(x in q for x in [
        "pozorovÃ¡no",
        "zaznamenÃ¡no",
        "pÅ™Ã­pady",
        "udÃ¡losti"
    ]):
        return ["raw", "synth"]

    if any(x in q for x in [
        "jak",
        "proÄ",
        "vzorce"
    ]):
        return ["synth", "meta"]

    if any(x in q for x in [
        "nevÃ­me",
        "zkreslenÃ­",
        "limity"
    ]):
        return ["meta", "synth"]

    return ["synth"]


# ---------- CORE ----------
def ask(question: str) -> str:

    if not question.strip():
        return "PrÃ¡zdnÃ½ dotaz."

    allowed_layers = classify_question(question)

    q_vec = embed_question_cached(question)

    distances, indices = index.search(q_vec, FAISS_K)

    if indices.size == 0:
        return run_reasoner(question)

    candidates = [chunks[i] for i in indices[0]]

    filtered = [
        c for c in candidates
        if c.get("layer") in allowed_layers
    ]

    # ğŸ‘‰ pokud nemÃ¡me evidenci â†’ druhÃ½ mozek
    if not filtered:
        return run_reasoner(question)

    priority_map = {layer: i for i, layer in enumerate(LAYER_PRIORITY)}

    filtered.sort(
        key=lambda c: priority_map.get(c["layer"], 999)
    )

    context_docs = filtered[:TOP_K]

    context = "\n\n".join(
        f"[VRSTVA: {c['layer']}]\n{c['text']}"
        for c in context_docs
    )

    prompt = f"""{SYSTEM_RULES}

KONTEXT:
{context}

OTÃZKA:
{question}
"""

    try:

        response = client.models.generate_content(
            model=LLM_MODEL,
            contents=prompt
        )

        if not response.text:
            return run_reasoner(question)

        text = response.text.strip()

        # ğŸ”¥ kritickÃ¡ pojistka
        if "NEDOLOÅ½ENO" in text:
            return run_reasoner(question)

        return text

    except Exception as e:

        print("LLM ERROR:", e)

        return run_reasoner(question)
